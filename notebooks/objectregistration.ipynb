{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "import panel as pn\n",
    "import os\n",
    "import os.path as osp\n",
    "from omegaconf import OmegaConf\n",
    "pv.set_plot_theme(\"document\")\n",
    "\n",
    "pn.extension('vtk')\n",
    "os.system('/usr/bin/Xvfb :99 -screen 0 1024x768x24 &')\n",
    "os.environ['DISPLAY'] = ':99'\n",
    "os.environ['PYVISTA_OFF_SCREEN'] = 'True'\n",
    "os.environ['PYVISTA_USE_PANEL'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from plyfile import PlyData\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_points3d.datasets.segmentation.scannet import Scannet\n",
    "from torch_points3d.datasets.oneshot_detection.scannet import ScannetOneShotDetection\n",
    "from torch_points3d.datasets.segmentation import IGNORE_LABEL\n",
    "from torch_points3d.core.data_transform import GridSampling3D, AddOnes, AddFeatByKey\n",
    "from torch_geometric.transforms import Compose\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_points3d.utils.registration import get_matches, fast_global_registration\n",
    "from torch_points3d.applications.pretrained_api import PretainedRegistry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aligning objects in scenes\n",
    "\n",
    "This notebooks explores ways to align objects in a scene with the idea that this could be used for object detection. Let's start by loading Scannet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = os.path.dirname(os.getcwd())\n",
    "ONE_SHOT_CLASS=4\n",
    "dataroot = os.path.join(DIR,\"data\",\"scannet-oneshot\")\n",
    "transform = Compose([GridSampling3D(mode='last', size=0.02, quantize_coords=True), AddOnes(), AddFeatByKey(add_to_x=True, feat_name=\"ones\")])\n",
    "dataset = ScannetOneShotDetection(dataroot,transform=transform)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(clouds, together=False, colors=[]):\n",
    "    viewers = []\n",
    "    for i,cloud in enumerate(clouds):\n",
    "        if not together or len(viewers) == 0:\n",
    "            v = pv.Plotter(notebook=True)\n",
    "            viewers.append(v)\n",
    "        if len(colors) > i:\n",
    "            color = colors[i]\n",
    "        else:\n",
    "            color = [0.9, 0.7, 0.1]\n",
    "        v.add_points(cloud.pos.numpy(), color=color)\n",
    "            \n",
    "    pan = [pn.panel(v.ren_win, sizing_mode='scale_both', aspect_ratio=1,orientation_widget=True,) for v in viewers]\n",
    "    if together:\n",
    "        return pan[0]\n",
    "    else:\n",
    "        return pn.Row(*pan)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instances(data, label_idx):\n",
    "    instances = []\n",
    "    unique_instances = torch.unique(data.instance_labels)[-1] + 1\n",
    "    for i in torch.unique(data.instance_labels):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        instance_mask = data.instance_labels == i\n",
    "        label = data.y[instance_mask][-1]\n",
    "        if label == label_idx:\n",
    "            instances.append(Data(pos = data.pos[instance_mask], x = data.x[instance_mask], coords = data.coords[instance_mask]))\n",
    "    return instances    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset[15]\n",
    "beds = get_instances(d, 3)\n",
    "beds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([d,beds[0]], together=True, colors = [[0.9, 0.7, 0.1],[0.1, 0.7, 0.9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will log some errors, don't worry it's all good!\n",
    "model = PretainedRegistry.from_pretrained(\"minkowski-registration-3dmatch\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_points3d.utils.geometry import euler_angles_to_rotation_matrix\n",
    "import random\n",
    "\n",
    "d15 =dataset[15]\n",
    "beds = get_instances(d15,3)\n",
    "bed15 = beds[0]\n",
    "\n",
    "d0= dataset[0]\n",
    "beds = get_instances(d0,3)\n",
    "bed0= beds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(data):\n",
    "    batch = Batch.from_data_list([data])\n",
    "    with torch.no_grad():\n",
    "        model.set_input(batch, \"cuda\")\n",
    "        output = model.forward()\n",
    "    return output\n",
    "\n",
    "def register(data, obj):\n",
    "    data_feat = compute_features(data)\n",
    "    obj_feats = compute_features(obj)\n",
    "    matches = get_matches(data_feat, obj_feats, sym=True)\n",
    "    print(\"Number of matches = %i\" %matches.shape[0])\n",
    "    T_est = fast_global_registration(obj.pos[matches[:, 1]],data.pos[matches[:, 0]])\n",
    "    transformed_obj = copy.deepcopy(obj)\n",
    "    transformed_obj.pos= obj.pos @ T_est[:3, :3].T + T_est[:3, 3]\n",
    "    return transformed_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = register(d0, bed15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([d0,transformed], together=True, colors = [[0.9, 0.7, 0.1],[0.1, 0.7, 0.9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matches(data,obj, max_lines=100):\n",
    "    d_feats = compute_features(data)\n",
    "    obj_feats = compute_features(obj)\n",
    "    matches = get_matches(d_feats, obj_feats, sym=True)\n",
    "    if matches.shape[0]>max_lines:\n",
    "        perm = torch.randperm(matches.shape[0])\n",
    "        idx = perm[:max_lines]\n",
    "        matches = matches[idx,:]\n",
    "    \n",
    "    v = pv.Plotter(notebook=True)\n",
    "    v.add_points(obj.pos.cpu().numpy())\n",
    "    moved_scan = data.pos.cpu().numpy() + np.asarray([5,0,0])\n",
    "    v.add_points(moved_scan)\n",
    "    for i in range(matches.shape[0]):\n",
    "        lines = []\n",
    "        lines.append(moved_scan[matches[i,0]])\n",
    "        lines.append(obj.pos[matches[i,1]].numpy())\n",
    "        v.add_lines(np.asarray(lines), width=5, color=\"green\")\n",
    "    return pn.panel(v.ren_win, sizing_mode='scale_both', aspect_ratio=1,orientation_widget=True,)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matches(d15, bed15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_points3d.datasets.object_detection.box_data import BoxData\n",
    "from torch_points3d.metrics.oneshottracker import OneShotObjectTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_points3d.utils.registration import teaser_pp_registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONE_SHOT_CLASS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegistrationResult:\n",
    "    def __init__(self,obj, class_label):\n",
    "        if obj == None:\n",
    "            self.box = None\n",
    "            return\n",
    "        \n",
    "        self.transformed_obj = obj\n",
    "        min_pos, max_pos = torch.min(obj.pos,0)[0],torch.max(obj.pos,0)[0]\n",
    "        xi,yi,zi = min_pos\n",
    "        xm, ym, zm = max_pos\n",
    "        corners = torch.tensor([\n",
    "            [xi,yi,zi], [ xm,yi, zi],[xm, ym, zi],[xi, ym, zi],\n",
    "            [xi,yi,zm], [ xm,yi, zi],[xm, ym, zm],[xi, ym, zm],\n",
    "        ])\n",
    "        self.box = BoxData(class_label, corners, 1)\n",
    "        \n",
    "    def get_boxes(self):\n",
    "        if self.box is not None:\n",
    "            return [[self.box]]\n",
    "        else:\n",
    "            return [[]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegistrationModel(torch.nn.Module):\n",
    "    def __init__(self,class_label, min_inliers = 10):\n",
    "        super().__init__()\n",
    "        self._min_inliers = min_inliers\n",
    "        self.class_label = class_label\n",
    "        self._model =  PretainedRegistry.from_pretrained(\"minkowski-registration-3dmatch\").cuda()\n",
    "    \n",
    "    def compute_features(self,data):\n",
    "        batch = Batch.from_data_list([data])\n",
    "        with torch.no_grad():\n",
    "            self._model.set_input(batch, \"cuda\")\n",
    "            output = self._model.forward()\n",
    "        return output\n",
    "\n",
    "    def forward(self, data,  one_instance):\n",
    "        data_feat = self.compute_features(data)\n",
    "        obj_feats = self.compute_features(one_instance)\n",
    "        matches = get_matches(data_feat, obj_feats, sym=True)\n",
    "\n",
    "        # T_est = fast_global_registration(one_instance.pos[matches[:, 1]],data.pos[matches[:, 0]])\n",
    "        T_est, inliers = teaser_pp_registration(one_instance.pos[matches[:, 1]],data.pos[matches[:, 0]])\n",
    "        if len(inliers) > self._min_inliers:\n",
    "            transformed_obj = copy.deepcopy(one_instance)\n",
    "            transformed_obj.pos= one_instance.pos @ T_est[:3, :3].T + T_est[:3, 3]\n",
    "            self.output = RegistrationResult(transformed_obj, self.class_label)\n",
    "        else:\n",
    "            self.output = RegistrationResult(None, self.class_label)\n",
    "        \n",
    "    def get_output(self):\n",
    "        return self.output\n",
    "    \n",
    "    def get_current_losses(self):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegistrationModel(dataset.NYU40ID2CLASS[ONE_SHOT_CLASS],min_inliers = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONE_SHOT_CLASS = 5\n",
    "d0 = dataset[5]\n",
    "bed0 = get_instances(d0, ONE_SHOT_CLASS)[0]\n",
    "# model(d0, bed15)\n",
    "# replaced = model.get_output().transformed_obj\n",
    "plot(get_instances(d0, ONE_SHOT_CLASS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed = transform(dataset.get_random_instance(ONE_SHOT_CLASS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "count = 0\n",
    "max_iter = 15\n",
    "tracker = OneShotObjectTracker(dataset)\n",
    "with tqdm.notebook.tqdm(dataset) as bar:\n",
    "    for d in bar:\n",
    "    #     d = dataset[i]\n",
    "        beds = get_instances(d, ONE_SHOT_CLASS)\n",
    "        if not len(beds):\n",
    "            continue\n",
    "        model(d, bed0)\n",
    "        tracker.track(model, Batch.from_data_list([d]))\n",
    "        count += 1\n",
    "        bar.set_postfix(**tracker.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker._tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
